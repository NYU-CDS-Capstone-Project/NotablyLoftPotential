{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import string\n",
    "import pickle\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim import corpora\n",
    "from gensim.models import ldamodel, Phrases, phrases\n",
    "from nltk import bigrams\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "\n",
    "class classifytweet:\n",
    "    def __init__(self, model_files='model_files/'):\n",
    "        \"\"\"\n",
    "        tweet_body: the individual tweet\n",
    "        model_files: the location for the model files. leave the model files folder as is\n",
    "                     unless you have changed the location of all the model files.\n",
    "        \"\"\"\n",
    "        self.model_files = model_files\n",
    "        #self.model, self.corpus, self.dictionary, self.phraser, self.valence_mean, self.arousal_mean, self.valence_sd, self.arousal_sd = self.load_model()\n",
    "        self.load_model()\n",
    "        self.n = len(self.dictionary.items())\n",
    "        self.word_map = {v:k for k,v in self.dictionary.items()}\n",
    "        print(\"Model items loaded and classifier initialized!\")\n",
    "        \n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Loads the model, corpus, and dictionary.\n",
    "        \"\"\"\n",
    "        # extract tarfiles\n",
    "        for f in os.listdir(self.model_files):\n",
    "            if f.endswith('.gz'):\n",
    "                tar = tarfile.open(self.model_files + f, \"r:gz\")\n",
    "                tar.extractall(path=self.model_files)\n",
    "                tar.close()\n",
    "\n",
    "        # load model, corpus, and dictionary objects\n",
    "        fnames = [fn for fn in os.listdir(self.model_files) if '.gensim' in fn]\n",
    "        self.model = ldamodel.LdaModel.load(self.model_files + fnames[0])\n",
    "        self.corpus = corpora.MmCorpus(self.model_files + 'unigrams_corpus.mm')\n",
    "        self.dictionary = corpora.Dictionary.load(self.model_files + 'unigrams_dictionary.pkl')\n",
    "        self.model.id2word = self.dictionary\n",
    "        self.phraser = phrases.Phrases.load(self.model_files + 'document_phraser.pkl')\n",
    "        for f in ['unigrams_dictionary.pkl', 'unigrams_corpus.mm', 'unigrams_corpus.mm.index', 'NB_vectorizer.pkl', 'NB_sentiment_model.pkl']:\n",
    "            fnames.append(f)\n",
    "        \n",
    "        # load the valence and arousal arrays\n",
    "        self.valence_mean = pickle.load(open(self.model_files + 'valence_mean.pkl', 'rb'))\n",
    "        self.arousal_mean = pickle.load(open(self.model_files + 'arousal_mean.pkl', 'rb'))\n",
    "        self.valence_sd = pickle.load(open(self.model_files + 'valence_sd.pkl', 'rb'))\n",
    "        self.arousal_sd = pickle.load(open(self.model_files + 'arousal_sd.pkl', 'rb'))\n",
    "        \n",
    "        # load the MinMaxScaler for the transforming the scores\n",
    "        self.base_outrage_scaler = None\n",
    "        self.expanded_outrage_scaler = None\n",
    "        self.valence_scaler = None\n",
    "        self.arousal_scaler = None\n",
    "        self.emoji_scaler = None\n",
    "        self.topic_valence_scaler = pickle.load(open(self.model_files + 'topic_valence_scaled.pkl', 'rb'))\n",
    "        self.topic_arousal_scaler = pickle.load(open(self.model_files + 'topic_arousal_scaled.pkl', 'rb'))\n",
    "        \n",
    "        # load the Naive Bayes sentiment model\n",
    "        try:\n",
    "            self.nb_model = pickle.load(open(self.model_files + 'NB_sentiment_model.pkl', 'rb'))\n",
    "        except:\n",
    "            self.nb_model = pickle.load(open(self.model_files + 'NB_sentiment_model.pkl', 'rb'), encoding='latin1')\n",
    "        try:\n",
    "            self.nb_vectorizer = pickle.load(open(self.model_files + 'NB_vectorizer.pkl', 'rb'))\n",
    "        except:\n",
    "            self.nb_vectorizer = pickle.load(open(self.model_files + 'NB_vectorizer.pkl', 'rb'), encoding='latin1')\n",
    "        \n",
    "        # load the outrage dictionaries\n",
    "        self.outrage_list = pd.read_csv(self.model_files + 'outrage_dictionary_stemmed.csv', header=None)\n",
    "        self.exp_outrage_list = pd.read_csv(self.model_files + 'expanded_outrage_dictionary_stemmed.csv', header=None)\n",
    "\n",
    "        # cleanup the unzipped files\n",
    "        for f in fnames:\n",
    "            os.remove(self.model_files + f)\n",
    "            \n",
    "        return \"All modeling information loaded\"\n",
    "\n",
    "    def prepare_tweet(self, tweet):\n",
    "        \"\"\"\n",
    "        Turn that unstructured text into sweet, sweet, \"cleaned\" up tokens!\n",
    "        \"\"\"\n",
    "        self.tweet = tweet\n",
    "        stemmer = SnowballStemmer(\"english\")\n",
    "        tokenizer = TweetTokenizer()\n",
    "        self.tweet_tokenized = tokenizer.tokenize(self.tweet)\n",
    "        try:\n",
    "            self.tweet_tokenized = [unicode(y.encode(\"utf-8\"), errors='ignore') for y in self.tweet_tokenized]\n",
    "            self.stemmed = [stemmer.stem(y) for y in self.tweet_tokenized]\n",
    "        except:\n",
    "            #tweet_tokenized = [y.encode(\"utf-8\") for y in tweet_tokenized]\n",
    "            self.stemmed = [stemmer.stem(y) for y in self.tweet_tokenized]\n",
    "        #self.stemmed = filter('', self.stemmed)\n",
    "        #self.processed = ''.join(self.stemmed)\n",
    "        #self.text_bigrams = [' '.join(self.stemmed[i:]) for i in range(2)]\n",
    "        self.text_bigrams=list(bigrams(self.stemmed))\n",
    "        self.text_bigrams=[\"%s %s\" % x for x in self.text_bigrams]\n",
    "        self.text_bigrams.extend(self.stemmed)\n",
    "\n",
    "        keep = set(['!','?'])\n",
    "        stop = set(stopwords.words('english'))\n",
    "        remove = set([x for x in list(string.punctuation) if x not in keep])\n",
    "        stop.update(remove)\n",
    "        stop.update(['',' ','  '])\n",
    "        stemmed = [d for d in self.stemmed if d not in stop]\n",
    "        self.phrased = list(self.phraser[[stemmed]])[0]\n",
    "\n",
    "        print('Phrased representation: \"' + ' '.join(self.phrased) + '\"')\n",
    "        #return None\n",
    "    \n",
    "    def get_valence_score(self):\n",
    "        \"\"\"\n",
    "        Creates the valence and arousal score for the tweet.\n",
    "        \"\"\"\n",
    "        tweet_arr = np.zeros(self.n)\n",
    "        for word in set(self.phrased) & set(self.word_map.keys()):\n",
    "            tweet_arr[self.word_map[word]] = 1.\n",
    "        mean = tweet_arr * self.valence_mean\n",
    "        sd = tweet_arr * self.valence_sd\n",
    "        total_sd = np.sum(sd) * tweet_arr\n",
    "        with np.errstate(divide='ignore'):\n",
    "            sd_ratio = total_sd / sd\n",
    "            sd_ratio[sd == 0] = 0\n",
    "        sd_weight = sd_ratio / np.sum(sd_ratio)\n",
    "        \n",
    "        self.valence_score = np.sum(mean*sd_weight)\n",
    "        \n",
    "        return self.valence_score\n",
    "\n",
    "    def get_arousal_score(self):\n",
    "        \"\"\"\n",
    "        Creates the valence and arousal score for the tweet.\n",
    "        \"\"\"\n",
    "        tweet_arr = np.zeros(self.n)\n",
    "        for word in set(self.phrased) & set(self.word_map.keys()):\n",
    "            tweet_arr[self.word_map[word]] = 1.\n",
    "        mean = tweet_arr * self.arousal_mean\n",
    "        sd = tweet_arr * self.arousal_sd\n",
    "        total_sd = np.sum(sd) * tweet_arr\n",
    "        with np.errstate(divide='ignore'):\n",
    "            sd_ratio = total_sd / sd\n",
    "            sd_ratio[sd == 0] = 0\n",
    "        sd_weight = sd_ratio / np.sum(sd_ratio)\n",
    "        \n",
    "        self.arousal_score = np.sum(mean*sd_weight)\n",
    "        \n",
    "        return self.arousal_score\n",
    "\n",
    "    def get_sentiment_score(self):\n",
    "        \"\"\"\n",
    "        Weights the posititive/negative sentiment of the tweet.\n",
    "        \"\"\"\n",
    "        vectorized = self.nb_vectorizer.transform(self.text_bigrams)\n",
    "        self.sentiment_score = np.average(1 - self.nb_model.predict_proba(vectorized)[:,1])\n",
    "\n",
    "        return self.sentiment_score\n",
    "\n",
    "    def get_topics(self):\n",
    "        \"\"\"\n",
    "        Extract the topics from the tweet using the LDA model.\n",
    "        \"\"\"\n",
    "        return self.model.get_document_topics(self.model.id2word.doc2bow(self.phrased), per_word_topics=False)\n",
    "\n",
    "    def get_emoji_count(self):\n",
    "        \"\"\"\n",
    "        Count the Mad! faces.\n",
    "        \"\"\"\n",
    "        positives = ['<U+0082>', '<U+008D>']\n",
    "        outrage = ['<U+00A0>', '<U+00A1>', '<U+00A4>', '<U+00A9>']\n",
    "        positive_score = sum([y in positives for y in self.tweet_tokenized])\n",
    "        outrage_score = sum([y in outrage for y in self.tweet_tokenized])\n",
    "        self.emoji_count = outrage_score-positive_score\n",
    "        return self.emoji_count\n",
    "\n",
    "    def get_base_outrage_count(self):\n",
    "        \"\"\"\n",
    "        Get the number of outrage words in the tweet.\n",
    "        \"\"\"\n",
    "        self.base_outrage_count = len(set(self.stemmed) & set(self.outrage_list))\n",
    "        return self.base_outrage_count\n",
    "\n",
    "    def get_expanded_outrage_count(self):\n",
    "        \"\"\"\n",
    "        Get the number of outrage words in the tweet.\n",
    "        \"\"\"\n",
    "        outrage = set(self.stemmed) & set(self.exp_outrage_list)\n",
    "        self.expanded_outrage_count = 0\n",
    "        for i in self.stemmed:\n",
    "            if i in (self.exp_outrage_list):\n",
    "                self.expanded_outrage_count += 1\n",
    "\n",
    "        return self.expanded_outrage_count\n",
    "\n",
    "    def get_outrage_score(self):\n",
    "        \"\"\"\n",
    "        Uses the results of each of the index measures to create one score.\n",
    "        .20 outrage dict\n",
    "        .15 expanded outrage dict\n",
    "        .15 valence\n",
    "        .13 arousal\n",
    "        .11 sentiment\n",
    "        .10 emoji\n",
    "        .08 topic valence\n",
    "        .08 topic arousal\n",
    "        \"\"\"\n",
    "        self.topics = self.get_topics()\n",
    "        topic_valence_score = 0\n",
    "        topic_arousal_score = 0\n",
    "        for tup in self.topics:\n",
    "            topic_valence_score += self.topic_valence_scaler[tup[0]] * tup[1]\n",
    "            topic_arousal_score += self.topic_valence_scaler[tup[0]] * tup[1]\n",
    "            \n",
    "        scores = np.array([\n",
    "            self.get_base_outrage_count(),\n",
    "            self.get_expanded_outrage_count(),\n",
    "            self.get_valence_score(),\n",
    "            self.get_arousal_score(),\n",
    "            self.get_sentiment_score(),\n",
    "            self.get_emoji_count(),\n",
    "            topic_valence_score,\n",
    "            topic_arousal_score\n",
    "            ])\n",
    "        weights = np.array([0.2, 0.15, 0.15, 0.13, 0.11, 0.10, 0.08, 0.08])\n",
    "\n",
    "        self.outrage_meter = np.sum(scores*weights)\n",
    "        return self.outrage_meter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model items loaded and classifier initialized!\n",
      "Took 0:00:21.018352 to initialize.\n"
     ]
    }
   ],
   "source": [
    "#import tweetclassifier\n",
    "from time import time\n",
    "import datetime\n",
    "\n",
    "t0 = time()\n",
    "tweeter = classifytweet()\n",
    "elapsed = time() - t0\n",
    "print(\"Took %s to initialize.\" % (str(datetime.timedelta(seconds=elapsed))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrased representation: \"scientist_say bear go extinct want peopl realiz look_like say photograph paul nicklen\"\n"
     ]
    }
   ],
   "source": [
    "tweeter.prepare_tweet('\"When scientists say bears are going extinct, I want people to realize what it looks like,\" says photographer Paul Nicklen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:129: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.7438875653772072"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter.get_valence_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:148: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.3143414353251792"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter.get_arousal_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.088334416350984671),\n",
       " (18, 0.09443194166093366),\n",
       " (30, 0.65034827955069929),\n",
       " (33, 0.089107584659602848)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter.get_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 3 0.037*\"wed_dress\" + 0.033*\"climat_chang\" + 0.020*\"greatest_threat\" + 0.018*\"ted_cruz\" + 0.013*\"hot\" + 0.009*\"...\" + 0.008*\"level\" + 0.008*\"ocean\" + 0.008*\"disast\" + 0.008*\"messag\" + 0.007*\"new\" + 0.007*\"#ourstolos\" + 0.006*\"greatest\" + 0.006*\"alert\" + 0.006*\"manag\"\n",
      "Topic 18 0.094*\"climat_chang\" + 0.039*\"link\" + 0.018*\"worri\" + 0.011*\"religion\" + 0.010*\"terror\" + 0.010*\"pay\" + 0.009*\"contribut\" + 0.009*\"@sensand\" + 0.009*\"evid\" + 0.008*\"stop\" + 0.008*\"...\" + 0.007*\"scam\" + 0.007*\"project\" + 0.006*\"side\" + 0.006*\"corpor\"\n",
      "Topic 30 0.025*\"marriag\" + 0.020*\"...\" + 0.018*\"like\" + 0.016*\"i'm\" + 0.014*\"one\" + 0.013*\"get\" + 0.013*\"don't\" + 0.012*\"go\" + 0.009*\"peopl\" + 0.009*\"know\" + 0.009*\"think\" + 0.008*\"thing\" + 0.008*\"would\" + 0.008*\"becaus\" + 0.007*\"guy\"\n",
      "Topic 33 0.025*\"women\" + 0.023*\"climat_chang\" + 0.017*\"#uniteblu_#tcot\" + 0.015*\"#scienc\" + 0.012*\"...\" + 0.008*\"marriag\" + 0.007*\"anniversari\" + 0.007*\"bet\" + 0.007*\"need\" + 0.005*\"inspir_action\" + 0.005*\"rt_song\" + 0.005*\"vid_#standorfal\" + 0.005*\"share_music\" + 0.005*\"https://t.co/hptv1jatyx_#parissummit\" + 0.005*\"technolog\"\n"
     ]
    }
   ],
   "source": [
    "for tup in tweeter.get_topics():\n",
    "    print(\"Topic\",tup[0],tweeter.model.print_topic(tup[0],topn=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49762867844555025"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter.get_sentiment_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter.get_emoji_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter.get_base_outrage_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter.get_expanded_outrage_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:129: RuntimeWarning: invalid value encountered in true_divide\n",
      "//anaconda/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:148: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.5889777124511231"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter.get_outrage_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.332, 'global_warm'),\n",
       " (0.013, 'new_york'),\n",
       " (0.013, '...'),\n",
       " (0.009, 'via_@dailycal'),\n",
       " (0.009, 'time'),\n",
       " (0.008, 'caus'),\n",
       " (0.007, 'predict'),\n",
       " (0.005, 'hoax'),\n",
       " (0.004, 'climat_chang'),\n",
       " (0.004, 'theori'),\n",
       " (0.004, 'excit'),\n",
       " (0.004, '#isi'),\n",
       " (0.004, 'obama'),\n",
       " (0.004, '#tcot'),\n",
       " (0.004, 'antarct_ice'),\n",
       " (0.003, '#forecast'),\n",
       " (0.003, 'develop'),\n",
       " (0.003, 'say'),\n",
       " (0.003, 'claim'),\n",
       " (0.003, 'crowd'),\n",
       " (0.003, 'trend'),\n",
       " (0.003, 'summer'),\n",
       " (0.003, 'gain_ice'),\n",
       " (0.003, 'send_forc'),\n",
       " (0.003, 'metorologist_fight'),\n",
       " (0.003, 'https://t.co/gprzfbifbm_obama'),\n",
       " (0.003, 'new'),\n",
       " (0.003, 'denial'),\n",
       " (0.003, 'enrich_famili'),\n",
       " (0.003, 'speed')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(float(x.split('*')[0]),x.split('*')[1][1:-1]) for x in tweeter.model.print_topics(num_topics=60, num_words=30)[0][1].split(\" + \")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
