{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.externals import joblib\n",
    "from gensim.models import ldamodel\n",
    "import gensim\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expanding Outrage Dictionary with word2vec Pretrained Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_csv('data_cleaned_w_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outrage = pd.read_csv('outrage_dictionary.csv', header=None)\n",
    "outrage_list = list(outrage[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outrage_list_expanded = outrage_list[:]\n",
    "for item in outrage_list:\n",
    "    temp_list = w2v_model.most_similar(positive=[item])[:5]\n",
    "    for words in temp_list:\n",
    "        outrage_list_expanded.append(words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outrage_list_expanded = [item.encode(\"utf-8\") for item in outrage_list_expanded]\n",
    "outrage_list_expanded=list(set(outrage_list_expanded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base['num_outrage_words_ext']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "df_base['text_tokenized'] = df_base[\"text\"].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asimonoff/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n"
     ]
    }
   ],
   "source": [
    "for j in range(len(df_base)):\n",
    "    if j%10000 == 0:\n",
    "        print j\n",
    "    for i in df_base.text_tokenized[j]:\n",
    "        if i in (outrage_list_expanded):\n",
    "            df_base['num_outrage_words_ext'][j]= df_base['num_outrage_words_ext'][j]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    525502\n",
       "1     25209\n",
       "2      2140\n",
       "3       207\n",
       "4        26\n",
       "5         2\n",
       "Name: num_outrage_words_ext, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base['num_outrage_words_ext'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asimonoff/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n"
     ]
    }
   ],
   "source": [
    "df_base['num_outrage_words']=0\n",
    "for j in range(len(df_base)):\n",
    "    if j%10000 == 0:\n",
    "        print j\n",
    "    for i in df_base.text_tokenized[j]:\n",
    "        if i in (outrage_list):\n",
    "            df_base['num_outrage_words'][j]= df_base['num_outrage_words'][j]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_base.to_csv('data_cleaned_w_sentiment_outrage_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user.description</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>log_followers</th>\n",
       "      <th>log_retweets</th>\n",
       "      <th>engagement_flag</th>\n",
       "      <th>text_token</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>positive_emo</th>\n",
       "      <th>outrage_emo</th>\n",
       "      <th>net_emo_outrage</th>\n",
       "      <th>predicted_sentiment</th>\n",
       "      <th>negative_sentiment_prob</th>\n",
       "      <th>num_outrage_words_ext</th>\n",
       "      <th>text_tokenized</th>\n",
       "      <th>num_outrage_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33308</th>\n",
       "      <td>pro-choice crusader, equal rights for all, dem...</td>\n",
       "      <td>@MorganBullion @Canine_Rights Gun whores are d...</td>\n",
       "      <td>G</td>\n",
       "      <td>7.627057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'@MorganBullion', u'@Canine_Rights', u'Gun',...</td>\n",
       "      <td>[u'@morganbullion', u'@canine_right', u'gun', ...</td>\n",
       "      <td>@morganbullion @canine_right gun whore are des...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.556514</td>\n",
       "      <td>5</td>\n",
       "      <td>[@MorganBullion, @Canine_Rights, Gun, whores, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374519</th>\n",
       "      <td>One man. One opinion, in a sea of ass holes. M...</td>\n",
       "      <td>Wrong on health care, wrong on Benghazi, wrong...</td>\n",
       "      <td>C</td>\n",
       "      <td>6.021023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>[u'Wrong', u'on', u'health', u'care', u',', u'...</td>\n",
       "      <td>[u'wrong', u'on', u'health', u'care', u',', u'...</td>\n",
       "      <td>wrong on health care , wrong on benghazi , wro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.692956</td>\n",
       "      <td>5</td>\n",
       "      <td>[Wrong, on, health, care, ,, wrong, on, Bengha...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         user.description  \\\n",
       "33308   pro-choice crusader, equal rights for all, dem...   \n",
       "374519  One man. One opinion, in a sea of ass holes. M...   \n",
       "\n",
       "                                                     text topic  \\\n",
       "33308   @MorganBullion @Canine_Rights Gun whores are d...     G   \n",
       "374519  Wrong on health care, wrong on Benghazi, wrong...     C   \n",
       "\n",
       "        log_followers  log_retweets  engagement_flag  \\\n",
       "33308        7.627057           0.0                0   \n",
       "374519       6.021023           0.0                0   \n",
       "\n",
       "                                               text_token  \\\n",
       "33308   [u'@MorganBullion', u'@Canine_Rights', u'Gun',...   \n",
       "374519  [u'Wrong', u'on', u'health', u'care', u',', u'...   \n",
       "\n",
       "                                             text_stemmed  \\\n",
       "33308   [u'@morganbullion', u'@canine_right', u'gun', ...   \n",
       "374519  [u'wrong', u'on', u'health', u'care', u',', u'...   \n",
       "\n",
       "                                           text_processed  positive_emo  \\\n",
       "33308   @morganbullion @canine_right gun whore are des...             0   \n",
       "374519  wrong on health care , wrong on benghazi , wro...             0   \n",
       "\n",
       "        outrage_emo  net_emo_outrage  predicted_sentiment  \\\n",
       "33308             0                0                    0   \n",
       "374519            0                0                    0   \n",
       "\n",
       "        negative_sentiment_prob  num_outrage_words_ext  \\\n",
       "33308                  0.556514                      5   \n",
       "374519                 0.692956                      5   \n",
       "\n",
       "                                           text_tokenized  num_outrage_words  \n",
       "33308   [@MorganBullion, @Canine_Rights, Gun, whores, ...                  3  \n",
       "374519  [Wrong, on, health, care, ,, wrong, on, Bengha...                  4  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_base[df_base['num_outrage_words_ext']==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
